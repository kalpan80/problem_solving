import logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s', filename='hyperparameter.log')
import asyncio

import joblib
import numpy as np
from dotenv import load_dotenv
from pydantic import BaseModel, Field
from sklearn.datasets import load_iris
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

from agents import Agent, Runner, function_tool
import ast

MODEL = 'gpt-4.1-mini'
load_dotenv()

filename = 'random_forest_model.joblib'

logging.info('Hello World')

@function_tool
def get_data():
    iris = load_iris()
    return iris.data,iris.target

@function_tool
def train(split:float, random_state: int, n_estimators: int) -> str:
    print('Model Training Invoked ',split,random_state, n_estimators)
    iris = load_iris()
    X,y = iris.data,iris.target
    X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=split,random_state=random_state)
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    model = RandomForestClassifier(n_estimators=n_estimators, random_state=random_state)
    model.fit(X_train_scaled,y_train)
    y_pred = model.predict(scaler.transform(X_test))
    joblib.dump(model, filename)
    return classification_report(y_test,y_pred)

@function_tool
def infer(X_test: str,y_test:str) -> str:
    print('Model Inference Invoked ',X_test, y_test)
    model = joblib.load(filename)
    scaler = StandardScaler()
    y_pred = model.predict(scaler.fit_transform(np.array(ast.literal_eval(X_test))))
    return classification_report(np.asarray(np.array(ast.literal_eval(y_test))),y_pred)


class SyntheticData(BaseModel):
    x_test: str = Field('The test data for the model')
    y_test: str = Field('The ground truth label for the model')


trainer_agent_tool = Agent(
        name="TrainerAgent",
        model=MODEL,
        instructions="You are a training agent. You need to use tools to train the agent."
                    "It expects a split value from 0.5 to 0.8, a random_state is any integer value,"
                    "and number of estimators for classifier, it should be a integer value from 20 to 50. You need to choose the values carefully for hyper paramater tuning",
        tools=[train]
    ).as_tool(tool_name='TrainerAgentTool', tool_description='Agent that invokes model training procedure using tools')

data_generator_agent_tool = Agent(
        name="SyntheticDataGenerator",
        model=MODEL,
        instructions="You are a synthetic data generator agent. You need to use tools to generate synthetic data for all classes in the dataset."
                     "Your string output should follow the format x_test = [[1,2,3],[4,5,6]] and y_test=[1,2,3]",
        tools=[get_data],
        output_type=SyntheticData,
    ).as_tool(tool_name='SyntheticDataGeneratorTool', tool_description='Synthetic data generator agent that creates sample data for testing')

validator_agent_tool = Agent(
        name="ValidatorAgent",
        model=MODEL,
        instructions="You are a validator agent. You need to use tools to invoke model inference. "
                     "The model would require the synthetic data generated from SythenticDataGeneratorTool as input."
                     "The model expects input in the format of string array. For example, [[1,2,3],[4,5,6]]",
        tools=[infer],
    ).as_tool(tool_name='ValidatorAgentTool',tool_description='Validator agent that checks model performance with synthetic data')

planning_agent = Agent(
        name="PlannerAgent",
        model=MODEL,
        instructions="You are a planning agent. Your job is to break down complex tasks into smaller manageable subtasks using sub agents."
                    "Your sub agents are as follows:"
                    "TrainerAgent: It trains the machine learning model for inference."
                    "SyntheticDataGenerator: It generates synthetic data for model testing. The synthetic data must be different than the dataset"
                    "ValidatorAgent: It uses the synthetic data to invoke the model inference and generate the test results."
                    "You plan and delegate tasks, and do not execute them. Model training needs to be executed before model validation can be invoked. "
                    "The training agent will create the model for validation agent, and the test data will be generated by synthetic data generator tool."
                     "The synthetic data that is generated from the tool needs to be used for validation agent tool."
                    "Please all the agents till accuracy of more than 95% is achieved on test results. Continue the process of synthetic data generation and validation for three iterations even if the desired accuracy is achieved."
                     "You will use only maximum 5 iterations for model retraining."
                    "While assigning tasks use the format:"
                    "1. <agent> : <task>"
                    "After all tasks are completed summarize the findings for the entire process and end with 'TERMINATE'.",
        tools=[trainer_agent_tool,data_generator_agent_tool,validator_agent_tool]
    )


async def execute():
    result = Runner.run_streamed(starting_agent=planning_agent,
                             input="Please start the process of hyperparamater tuning, and generate the results",
                             max_turns=50)

    print("=== Run starting ===")
    
    # Iterate through the event stream to capture and display events
    async for event in result.stream_events():
        logging.info(event)
        """
        if event.type == "raw_response_event" and not (event.data.type=='response.function_call_arguments.delta' or event.data.type=='response.output_text.delta'):
            logging.info(event)
        """
        if event.type == "raw_response_event":
            if event.data.type == "response.output_text.done":
                print(event.data.text)
            """
            elif event.data.item.type == 'response.output_item.done':
                print(event.data.item.arguments)            
            elif event.data.type=='response.completed':
            """
        if event.type == 'run_item_stream_event':
            if event.name == 'tool_called' and event.item.raw_item.status == 'completed':
                print(event.item.raw_item.arguments)
            if event.name == 'tool_output':
                print(event.item.output)

    print("\n=== Run complete ===")
    print(result.final_output)

if __name__ == "__main__":
    asyncio.run(execute())